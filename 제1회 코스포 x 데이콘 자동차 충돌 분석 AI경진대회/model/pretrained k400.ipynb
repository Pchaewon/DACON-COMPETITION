{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74459b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cac5a52-9eb9-4bb7-aa62-b7c419273eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/XuezheMax/apollo/blob/master/optim/apollo.py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "\n",
    "class Apollo(Optimizer):\n",
    "    r\"\"\"Implements Atom algorithm.\n",
    "        Arguments:\n",
    "            params (iterable): iterable of parameters to optimize or dicts defining\n",
    "                parameter groups\n",
    "            lr (float): learning rate\n",
    "            beta (float, optional): coefficient used for computing running averages of gradient (default: 0.9)\n",
    "            eps (float, optional): term added to the denominator to improve numerical stability (default: 1e-4)\n",
    "            rebound (str, optional): recified bound for diagonal hessian:\n",
    "                ``'constant'`` | ``'belief'`` (default: None)\n",
    "            warmup (int, optional): number of warmup steps (default: 500)\n",
    "            init_lr (float, optional): initial learning rate for warmup (default: lr/1000)\n",
    "            weight_decay (float, optional): weight decay coefficient (default: 0)\n",
    "            weight_decay_type (str, optional): type of weight decay:\n",
    "                ``'L2'`` | ``'decoupled'`` | ``'stable'`` (default: 'L2')\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr, beta=0.9, eps=1e-4, rebound='constant', warmup=500, init_lr=None, weight_decay=0, weight_decay_type=None):\n",
    "        if not 0.0 < lr:\n",
    "            raise ValueError(\"Invalid learning rate value: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= beta < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(beta))\n",
    "        if rebound not in ['constant', 'belief']:\n",
    "            raise ValueError(\"Invalid recitifed bound: {}\".format(rebound))\n",
    "        if not 0.0 <= warmup:\n",
    "            raise ValueError(\"Invalid warmup updates: {}\".format(warmup))\n",
    "        if init_lr is None:\n",
    "            init_lr = lr / 1000\n",
    "        if not 0.0 <= init_lr <= lr:\n",
    "            raise ValueError(\"Invalid initial learning rate: {}\".format(init_lr))\n",
    "        if not 0.0 <= weight_decay:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        if weight_decay_type is None:\n",
    "            weight_decay_type = 'L2' if rebound == 'constant' else 'decoupled'\n",
    "        if weight_decay_type not in ['L2', 'decoupled', 'stable']:\n",
    "            raise ValueError(\"Invalid weight decay type: {}\".format(weight_decay_type))\n",
    "\n",
    "        defaults = dict(lr=lr, beta=beta, eps=eps, rebound=rebound,\n",
    "                        warmup=warmup, init_lr=init_lr, base_lr=lr,\n",
    "                        weight_decay=weight_decay, weight_decay_type=weight_decay_type)\n",
    "        super(Apollo, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(Apollo, self).__setstate__(state)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg_grad'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['approx_hessian'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "                    # Previous update direction\n",
    "                    state['update'] = torch.zeros_like(p, memory_format=torch.preserve_format)\n",
    "\n",
    "                # Calculate current lr\n",
    "                if state['step'] < group['warmup']:\n",
    "                    curr_lr = (group['base_lr'] - group['init_lr']) * state['step'] / group['warmup'] + group['init_lr']\n",
    "                else:\n",
    "                    curr_lr = group['lr']\n",
    "\n",
    "                # Perform optimization step\n",
    "                grad = p.grad\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Atom does not support sparse gradients.')\n",
    "\n",
    "                # Perform step weight decay\n",
    "                if group['weight_decay'] != 0 and group['weight_decay_type'] == 'L2':\n",
    "                    grad = grad.add(p, alpha=group['weight_decay'])\n",
    "\n",
    "                beta = group['beta']\n",
    "                eps = group['eps']\n",
    "                exp_avg_grad = state['exp_avg_grad']\n",
    "                B = state['approx_hessian']\n",
    "                d_p = state['update']\n",
    "\n",
    "                state['step'] += 1\n",
    "                bias_correction = 1 - beta ** state['step']\n",
    "                alpha = (1 - beta) / bias_correction\n",
    "\n",
    "                # calc the diff grad\n",
    "                delta_grad = grad - exp_avg_grad\n",
    "                if group['rebound'] == 'belief':\n",
    "                    rebound = delta_grad.norm(p=np.inf)\n",
    "                else:\n",
    "                    rebound = 0.01\n",
    "                    eps = eps / rebound\n",
    "\n",
    "                # Update the running average grad\n",
    "                exp_avg_grad.add_(delta_grad, alpha=alpha)\n",
    "\n",
    "                denom = d_p.norm(p=4).add(eps)\n",
    "                d_p.div_(denom)\n",
    "                v_sq = d_p.mul(d_p)\n",
    "                delta = delta_grad.div_(denom).mul_(d_p).sum().mul(-alpha) - B.mul(v_sq).sum()\n",
    "\n",
    "                # Update B\n",
    "                B.addcmul_(v_sq, delta)\n",
    "\n",
    "                # calc direction of parameter updates\n",
    "                if group['rebound'] == 'belief':\n",
    "                    denom = torch.max(B.abs(), rebound).add_(eps / alpha)\n",
    "                else:\n",
    "                    denom = B.abs().clamp_(min=rebound)\n",
    "\n",
    "                d_p.copy_(exp_avg_grad.div(denom))\n",
    "\n",
    "                # Perform step weight decay\n",
    "                if group['weight_decay'] != 0 and group['weight_decay_type'] != 'L2':\n",
    "                    if group['weight_decay_type'] == 'stable':\n",
    "                        weight_decay = group['weight_decay'] / denom.mean().item()\n",
    "                    else:\n",
    "                        weight_decay = group['weight_decay']\n",
    "                    d_p.add_(p, alpha=weight_decay)\n",
    "\n",
    "                p.add_(d_p, alpha=-curr_lr)\n",
    "\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8e4a2b-70dd-4bcc-9eca-6af9b217e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/issamemari/pytorch-multilabel-balanced-sampler/blob/master/sampler.py\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "\n",
    "class MultilabelBalancedRandomSampler(Sampler):\n",
    "    \"\"\"\n",
    "    MultilabelBalancedRandomSampler: Given a multilabel dataset of length n_samples and\n",
    "    number of classes n_classes, samples from the data with equal probability per class\n",
    "    effectively oversampling minority classes and undersampling majority classes at the\n",
    "    same time. Note that using this sampler does not guarantee that the distribution of\n",
    "    classes in the output samples will be uniform, since the dataset is multilabel and\n",
    "    sampling is based on a single class. This does however guarantee that all classes\n",
    "    will have at least batch_size / n_classes samples as batch_size approaches infinity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, indices=None, class_choice=\"least_sampled\"):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "            labels: a multi-hot encoding numpy array of shape (n_samples, n_classes)\n",
    "            indices: an arbitrary-length 1-dimensional numpy array representing a list\n",
    "            of indices to sample only from\n",
    "            class_choice: a string indicating how class will be selected for every\n",
    "            sample:\n",
    "                \"least_sampled\": class with the least number of sampled labels so far\n",
    "                \"random\": class is chosen uniformly at random\n",
    "                \"cycle\": the sampler cycles through the classes sequentially\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.indices = indices\n",
    "        if self.indices is None:\n",
    "            self.indices = range(len(labels))\n",
    "\n",
    "        self.num_classes = self.labels.shape[1]\n",
    "\n",
    "        # List of lists of example indices per class\n",
    "        self.class_indices = []\n",
    "        for class_ in range(self.num_classes):\n",
    "            lst = np.where(self.labels[:, class_] == 1)[0]\n",
    "            lst = lst[np.isin(lst, self.indices)]\n",
    "            self.class_indices.append(lst)\n",
    "\n",
    "        self.counts = [0] * self.num_classes\n",
    "\n",
    "        assert class_choice in [\"least_sampled\", \"random\", \"cycle\"]\n",
    "        self.class_choice = class_choice\n",
    "        self.current_class = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.count >= len(self.indices):\n",
    "            raise StopIteration\n",
    "        self.count += 1\n",
    "        return self.sample()\n",
    "\n",
    "    def sample(self):\n",
    "        class_ = self.get_class()\n",
    "        class_indices = self.class_indices[class_]\n",
    "        chosen_index = np.random.choice(class_indices)\n",
    "        if self.class_choice == \"least_sampled\":\n",
    "            for class_, indicator in enumerate(self.labels[chosen_index]):\n",
    "                if indicator == 1:\n",
    "                    self.counts[class_] += 1\n",
    "        return chosen_index\n",
    "\n",
    "    def get_class(self):\n",
    "        if self.class_choice == \"random\":\n",
    "            class_ = random.randint(0, self.labels.shape[1] - 1)\n",
    "        elif self.class_choice == \"cycle\":\n",
    "            class_ = self.current_class\n",
    "            self.current_class = (self.current_class + 1) % self.labels.shape[1]\n",
    "        elif self.class_choice == \"least_sampled\":\n",
    "            min_count = self.counts[0]\n",
    "            min_classes = [0]\n",
    "            for class_ in range(1, self.num_classes):\n",
    "                if self.counts[class_] < min_count:\n",
    "                    min_count = self.counts[class_]\n",
    "                    min_classes = [class_]\n",
    "                if self.counts[class_] == min_count:\n",
    "                    min_classes.append(class_)\n",
    "            class_ = np.random.choice(min_classes)\n",
    "        return class_\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf9651e-e42f-4b43-a52c-54d8b6fb58bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from einops import rearrange\n",
    "from decord import VideoReader\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from segmentation_models_pytorch.losses import FocalLoss\n",
    "from transformers import AutoModel, AutoImageProcessor, AutoConfig\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorchvideo.transforms.transforms_factory import create_video_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2f4247e-f74d-4323-8005-242038d992a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\":2023,\n",
    "    \"model_name\":\"facebook/timesformer-base-finetuned-k400\",\n",
    "    \"batch_size\":3,\n",
    "    \"learning_rate\":1e-5,\n",
    "    \"data_dir\":'./',\n",
    "    \"checkpoint_dir\":'./checkpoint2',\n",
    "    #\"submission_dir\":'./submission',\n",
    "    \"n_classes\":(2,3,4,3),\n",
    "    \"label_dict\":{\n",
    "        -1:[-1,-1,-1,-1],\n",
    "        0:[0,0,0,0],\n",
    "        1:[1,1,1,1],\n",
    "        2:[1,1,1,2],\n",
    "        3:[1,1,2,1],\n",
    "        4:[1,1,2,2],\n",
    "        5:[1,1,3,1],\n",
    "        6:[1,1,3,2],\n",
    "        7:[1,2,1,1],\n",
    "        8:[1,2,1,2],\n",
    "        9:[1,2,2,1],\n",
    "        10:[1,2,2,2],\n",
    "        11:[1,2,3,1],\n",
    "        12:[1,2,3,2]\n",
    "    },\n",
    "    \"label_reverse_dict\":{\n",
    "        (0,0,0,0):0,\n",
    "        (1,1,1,1):1,\n",
    "        (1,1,1,2):2,\n",
    "        (1,1,2,1):3,\n",
    "        (1,1,2,2):4,\n",
    "        (1,1,3,1):5,\n",
    "        (1,1,3,2):6,\n",
    "        (1,2,1,1):7,\n",
    "        (1,2,1,2):8,\n",
    "        (1,2,2,1):9,\n",
    "        (1,2,2,2):10,\n",
    "        (1,2,3,1):11,\n",
    "        (1,2,3,2):12,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7430352-4e4d-414b-a180-ec554b3c9441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(config['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0a1692b-89ab-4739-a668-a191d43d85d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{config['data_dir']}/train.csv\")\n",
    "test_df = pd.read_csv(f\"{config['data_dir']}/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04928136-a408-4278-acbb-6284073c853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sample_id'] = train_df['sample_id'].apply(lambda x: int(x.split('_')[1]))\n",
    "test_df['sample_id'] = test_df['sample_id'].apply(lambda x: int(x.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a728f070-8d8f-4961-9258-bb482aea315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['video_path'] = train_df['video_path'].apply(lambda x: config['data_dir'] + x[1:])\n",
    "test_df['video_path'] = test_df['video_path'].apply(lambda x: config['data_dir'] + x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0403f478-2bb1-4ab6-8589-86d1ffc8e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['label']=-1\n",
    "test_df['label_split'] = test_df['label'].apply(config['label_dict'].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ba29cd0-c1da-43ab-a68c-b09688c70576",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label_split'] = train_df['label'].apply(config['label_dict'].get)\n",
    "train_label_split = np.array(train_df['label_split'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eac6350-eef7-4f10-b9e1-65ed21fd00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_multi_hot = np.hstack([np.eye(n_class, dtype=np.int32)[train_label_split[:,idx]] for idx, n_class in enumerate(config['n_classes'])])\n",
    "train_df['label_multi_hot'] = train_label_multi_hot.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4be86239-8eb6-4a4d-9b7c-08e5ae197ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_for_dataset, _ , val_df_for_dataset, _  = iterative_train_test_split(X=train_df.values, y=train_label_multi_hot, test_size=0.2)\n",
    "test_df_for_dataset = test_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b69d041-f0d9-4ba9-94df-e70aedb58319",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_multi_hot_for_sampler = np.array(train_df_for_dataset[:,4].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f4029b-f6e6-4b17-82c3-fb898fcec84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, df_for_dataset, transform=None):\n",
    "        self.sample_id = df_for_dataset[:,0]\n",
    "        self.video_path = df_for_dataset[:,1]\n",
    "        self.label = df_for_dataset[:,2]\n",
    "        self.label_split = np.array(df_for_dataset[:,3].tolist())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_id)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample_id = self.sample_id[idx]\n",
    "        video_path = self.video_path[idx]\n",
    "        vr = VideoReader(video_path)\n",
    "        video = torch.from_numpy(vr.get_batch(range(50)).asnumpy())\n",
    "        video = rearrange(video, 't h w c -> c t h w')\n",
    "        label = self.label[idx]\n",
    "        label_split = self.label_split[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            video = self.transform(video)\n",
    "        video = rearrange(video, 'c t h w -> t c h w')\n",
    "\n",
    "        sample = {\n",
    "            'sample_id':sample_id,\n",
    "            'video':video,\n",
    "            'label':label,\n",
    "            'label_split':label_split\n",
    "        }\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d84d5626-6b8b-4ea9-81a8-3320337d93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = AutoConfig.from_pretrained(config['model_name'])\n",
    "image_processor_config = AutoImageProcessor.from_pretrained(config['model_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "223f16bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesformerConfig {\n",
       "  \"_name_or_path\": \"facebook/timesformer-base-finetuned-k400\",\n",
       "  \"architectures\": [\n",
       "    \"TimesformerForVideoClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.0,\n",
       "  \"attention_type\": \"divided_space_time\",\n",
       "  \"drop_path_rate\": 0,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.0,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"abseiling\",\n",
       "    \"1\": \"air drumming\",\n",
       "    \"2\": \"answering questions\",\n",
       "    \"3\": \"applauding\",\n",
       "    \"4\": \"applying cream\",\n",
       "    \"5\": \"archery\",\n",
       "    \"6\": \"arm wrestling\",\n",
       "    \"7\": \"arranging flowers\",\n",
       "    \"8\": \"assembling computer\",\n",
       "    \"9\": \"auctioning\",\n",
       "    \"10\": \"baby waking up\",\n",
       "    \"11\": \"baking cookies\",\n",
       "    \"12\": \"balloon blowing\",\n",
       "    \"13\": \"bandaging\",\n",
       "    \"14\": \"barbequing\",\n",
       "    \"15\": \"bartending\",\n",
       "    \"16\": \"beatboxing\",\n",
       "    \"17\": \"bee keeping\",\n",
       "    \"18\": \"belly dancing\",\n",
       "    \"19\": \"bench pressing\",\n",
       "    \"20\": \"bending back\",\n",
       "    \"21\": \"bending metal\",\n",
       "    \"22\": \"biking through snow\",\n",
       "    \"23\": \"blasting sand\",\n",
       "    \"24\": \"blowing glass\",\n",
       "    \"25\": \"blowing leaves\",\n",
       "    \"26\": \"blowing nose\",\n",
       "    \"27\": \"blowing out candles\",\n",
       "    \"28\": \"bobsledding\",\n",
       "    \"29\": \"bookbinding\",\n",
       "    \"30\": \"bouncing on trampoline\",\n",
       "    \"31\": \"bowling\",\n",
       "    \"32\": \"braiding hair\",\n",
       "    \"33\": \"breading or breadcrumbing\",\n",
       "    \"34\": \"breakdancing\",\n",
       "    \"35\": \"brush painting\",\n",
       "    \"36\": \"brushing hair\",\n",
       "    \"37\": \"brushing teeth\",\n",
       "    \"38\": \"building cabinet\",\n",
       "    \"39\": \"building shed\",\n",
       "    \"40\": \"bungee jumping\",\n",
       "    \"41\": \"busking\",\n",
       "    \"42\": \"canoeing or kayaking\",\n",
       "    \"43\": \"capoeira\",\n",
       "    \"44\": \"carrying baby\",\n",
       "    \"45\": \"cartwheeling\",\n",
       "    \"46\": \"carving pumpkin\",\n",
       "    \"47\": \"catching fish\",\n",
       "    \"48\": \"catching or throwing baseball\",\n",
       "    \"49\": \"catching or throwing frisbee\",\n",
       "    \"50\": \"catching or throwing softball\",\n",
       "    \"51\": \"celebrating\",\n",
       "    \"52\": \"changing oil\",\n",
       "    \"53\": \"changing wheel\",\n",
       "    \"54\": \"checking tires\",\n",
       "    \"55\": \"cheerleading\",\n",
       "    \"56\": \"chopping wood\",\n",
       "    \"57\": \"clapping\",\n",
       "    \"58\": \"clay pottery making\",\n",
       "    \"59\": \"clean and jerk\",\n",
       "    \"60\": \"cleaning floor\",\n",
       "    \"61\": \"cleaning gutters\",\n",
       "    \"62\": \"cleaning pool\",\n",
       "    \"63\": \"cleaning shoes\",\n",
       "    \"64\": \"cleaning toilet\",\n",
       "    \"65\": \"cleaning windows\",\n",
       "    \"66\": \"climbing a rope\",\n",
       "    \"67\": \"climbing ladder\",\n",
       "    \"68\": \"climbing tree\",\n",
       "    \"69\": \"contact juggling\",\n",
       "    \"70\": \"cooking chicken\",\n",
       "    \"71\": \"cooking egg\",\n",
       "    \"72\": \"cooking on campfire\",\n",
       "    \"73\": \"cooking sausages\",\n",
       "    \"74\": \"counting money\",\n",
       "    \"75\": \"country line dancing\",\n",
       "    \"76\": \"cracking neck\",\n",
       "    \"77\": \"crawling baby\",\n",
       "    \"78\": \"crossing river\",\n",
       "    \"79\": \"crying\",\n",
       "    \"80\": \"curling hair\",\n",
       "    \"81\": \"cutting nails\",\n",
       "    \"82\": \"cutting pineapple\",\n",
       "    \"83\": \"cutting watermelon\",\n",
       "    \"84\": \"dancing ballet\",\n",
       "    \"85\": \"dancing charleston\",\n",
       "    \"86\": \"dancing gangnam style\",\n",
       "    \"87\": \"dancing macarena\",\n",
       "    \"88\": \"deadlifting\",\n",
       "    \"89\": \"decorating the christmas tree\",\n",
       "    \"90\": \"digging\",\n",
       "    \"91\": \"dining\",\n",
       "    \"92\": \"disc golfing\",\n",
       "    \"93\": \"diving cliff\",\n",
       "    \"94\": \"dodgeball\",\n",
       "    \"95\": \"doing aerobics\",\n",
       "    \"96\": \"doing laundry\",\n",
       "    \"97\": \"doing nails\",\n",
       "    \"98\": \"drawing\",\n",
       "    \"99\": \"dribbling basketball\",\n",
       "    \"100\": \"drinking\",\n",
       "    \"101\": \"drinking beer\",\n",
       "    \"102\": \"drinking shots\",\n",
       "    \"103\": \"driving car\",\n",
       "    \"104\": \"driving tractor\",\n",
       "    \"105\": \"drop kicking\",\n",
       "    \"106\": \"drumming fingers\",\n",
       "    \"107\": \"dunking basketball\",\n",
       "    \"108\": \"dying hair\",\n",
       "    \"109\": \"eating burger\",\n",
       "    \"110\": \"eating cake\",\n",
       "    \"111\": \"eating carrots\",\n",
       "    \"112\": \"eating chips\",\n",
       "    \"113\": \"eating doughnuts\",\n",
       "    \"114\": \"eating hotdog\",\n",
       "    \"115\": \"eating ice cream\",\n",
       "    \"116\": \"eating spaghetti\",\n",
       "    \"117\": \"eating watermelon\",\n",
       "    \"118\": \"egg hunting\",\n",
       "    \"119\": \"exercising arm\",\n",
       "    \"120\": \"exercising with an exercise ball\",\n",
       "    \"121\": \"extinguishing fire\",\n",
       "    \"122\": \"faceplanting\",\n",
       "    \"123\": \"feeding birds\",\n",
       "    \"124\": \"feeding fish\",\n",
       "    \"125\": \"feeding goats\",\n",
       "    \"126\": \"filling eyebrows\",\n",
       "    \"127\": \"finger snapping\",\n",
       "    \"128\": \"fixing hair\",\n",
       "    \"129\": \"flipping pancake\",\n",
       "    \"130\": \"flying kite\",\n",
       "    \"131\": \"folding clothes\",\n",
       "    \"132\": \"folding napkins\",\n",
       "    \"133\": \"folding paper\",\n",
       "    \"134\": \"front raises\",\n",
       "    \"135\": \"frying vegetables\",\n",
       "    \"136\": \"garbage collecting\",\n",
       "    \"137\": \"gargling\",\n",
       "    \"138\": \"getting a haircut\",\n",
       "    \"139\": \"getting a tattoo\",\n",
       "    \"140\": \"giving or receiving award\",\n",
       "    \"141\": \"golf chipping\",\n",
       "    \"142\": \"golf driving\",\n",
       "    \"143\": \"golf putting\",\n",
       "    \"144\": \"grinding meat\",\n",
       "    \"145\": \"grooming dog\",\n",
       "    \"146\": \"grooming horse\",\n",
       "    \"147\": \"gymnastics tumbling\",\n",
       "    \"148\": \"hammer throw\",\n",
       "    \"149\": \"headbanging\",\n",
       "    \"150\": \"headbutting\",\n",
       "    \"151\": \"high jump\",\n",
       "    \"152\": \"high kick\",\n",
       "    \"153\": \"hitting baseball\",\n",
       "    \"154\": \"hockey stop\",\n",
       "    \"155\": \"holding snake\",\n",
       "    \"156\": \"hopscotch\",\n",
       "    \"157\": \"hoverboarding\",\n",
       "    \"158\": \"hugging\",\n",
       "    \"159\": \"hula hooping\",\n",
       "    \"160\": \"hurdling\",\n",
       "    \"161\": \"hurling (sport)\",\n",
       "    \"162\": \"ice climbing\",\n",
       "    \"163\": \"ice fishing\",\n",
       "    \"164\": \"ice skating\",\n",
       "    \"165\": \"ironing\",\n",
       "    \"166\": \"javelin throw\",\n",
       "    \"167\": \"jetskiing\",\n",
       "    \"168\": \"jogging\",\n",
       "    \"169\": \"juggling balls\",\n",
       "    \"170\": \"juggling fire\",\n",
       "    \"171\": \"juggling soccer ball\",\n",
       "    \"172\": \"jumping into pool\",\n",
       "    \"173\": \"jumpstyle dancing\",\n",
       "    \"174\": \"kicking field goal\",\n",
       "    \"175\": \"kicking soccer ball\",\n",
       "    \"176\": \"kissing\",\n",
       "    \"177\": \"kitesurfing\",\n",
       "    \"178\": \"knitting\",\n",
       "    \"179\": \"krumping\",\n",
       "    \"180\": \"laughing\",\n",
       "    \"181\": \"laying bricks\",\n",
       "    \"182\": \"long jump\",\n",
       "    \"183\": \"lunge\",\n",
       "    \"184\": \"making a cake\",\n",
       "    \"185\": \"making a sandwich\",\n",
       "    \"186\": \"making bed\",\n",
       "    \"187\": \"making jewelry\",\n",
       "    \"188\": \"making pizza\",\n",
       "    \"189\": \"making snowman\",\n",
       "    \"190\": \"making sushi\",\n",
       "    \"191\": \"making tea\",\n",
       "    \"192\": \"marching\",\n",
       "    \"193\": \"massaging back\",\n",
       "    \"194\": \"massaging feet\",\n",
       "    \"195\": \"massaging legs\",\n",
       "    \"196\": \"massaging person's head\",\n",
       "    \"197\": \"milking cow\",\n",
       "    \"198\": \"mopping floor\",\n",
       "    \"199\": \"motorcycling\",\n",
       "    \"200\": \"moving furniture\",\n",
       "    \"201\": \"mowing lawn\",\n",
       "    \"202\": \"news anchoring\",\n",
       "    \"203\": \"opening bottle\",\n",
       "    \"204\": \"opening present\",\n",
       "    \"205\": \"paragliding\",\n",
       "    \"206\": \"parasailing\",\n",
       "    \"207\": \"parkour\",\n",
       "    \"208\": \"passing American football (in game)\",\n",
       "    \"209\": \"passing American football (not in game)\",\n",
       "    \"210\": \"peeling apples\",\n",
       "    \"211\": \"peeling potatoes\",\n",
       "    \"212\": \"petting animal (not cat)\",\n",
       "    \"213\": \"petting cat\",\n",
       "    \"214\": \"picking fruit\",\n",
       "    \"215\": \"planting trees\",\n",
       "    \"216\": \"plastering\",\n",
       "    \"217\": \"playing accordion\",\n",
       "    \"218\": \"playing badminton\",\n",
       "    \"219\": \"playing bagpipes\",\n",
       "    \"220\": \"playing basketball\",\n",
       "    \"221\": \"playing bass guitar\",\n",
       "    \"222\": \"playing cards\",\n",
       "    \"223\": \"playing cello\",\n",
       "    \"224\": \"playing chess\",\n",
       "    \"225\": \"playing clarinet\",\n",
       "    \"226\": \"playing controller\",\n",
       "    \"227\": \"playing cricket\",\n",
       "    \"228\": \"playing cymbals\",\n",
       "    \"229\": \"playing didgeridoo\",\n",
       "    \"230\": \"playing drums\",\n",
       "    \"231\": \"playing flute\",\n",
       "    \"232\": \"playing guitar\",\n",
       "    \"233\": \"playing harmonica\",\n",
       "    \"234\": \"playing harp\",\n",
       "    \"235\": \"playing ice hockey\",\n",
       "    \"236\": \"playing keyboard\",\n",
       "    \"237\": \"playing kickball\",\n",
       "    \"238\": \"playing monopoly\",\n",
       "    \"239\": \"playing organ\",\n",
       "    \"240\": \"playing paintball\",\n",
       "    \"241\": \"playing piano\",\n",
       "    \"242\": \"playing poker\",\n",
       "    \"243\": \"playing recorder\",\n",
       "    \"244\": \"playing saxophone\",\n",
       "    \"245\": \"playing squash or racquetball\",\n",
       "    \"246\": \"playing tennis\",\n",
       "    \"247\": \"playing trombone\",\n",
       "    \"248\": \"playing trumpet\",\n",
       "    \"249\": \"playing ukulele\",\n",
       "    \"250\": \"playing violin\",\n",
       "    \"251\": \"playing volleyball\",\n",
       "    \"252\": \"playing xylophone\",\n",
       "    \"253\": \"pole vault\",\n",
       "    \"254\": \"presenting weather forecast\",\n",
       "    \"255\": \"pull ups\",\n",
       "    \"256\": \"pumping fist\",\n",
       "    \"257\": \"pumping gas\",\n",
       "    \"258\": \"punching bag\",\n",
       "    \"259\": \"punching person (boxing)\",\n",
       "    \"260\": \"push up\",\n",
       "    \"261\": \"pushing car\",\n",
       "    \"262\": \"pushing cart\",\n",
       "    \"263\": \"pushing wheelchair\",\n",
       "    \"264\": \"reading book\",\n",
       "    \"265\": \"reading newspaper\",\n",
       "    \"266\": \"recording music\",\n",
       "    \"267\": \"riding a bike\",\n",
       "    \"268\": \"riding camel\",\n",
       "    \"269\": \"riding elephant\",\n",
       "    \"270\": \"riding mechanical bull\",\n",
       "    \"271\": \"riding mountain bike\",\n",
       "    \"272\": \"riding mule\",\n",
       "    \"273\": \"riding or walking with horse\",\n",
       "    \"274\": \"riding scooter\",\n",
       "    \"275\": \"riding unicycle\",\n",
       "    \"276\": \"ripping paper\",\n",
       "    \"277\": \"robot dancing\",\n",
       "    \"278\": \"rock climbing\",\n",
       "    \"279\": \"rock scissors paper\",\n",
       "    \"280\": \"roller skating\",\n",
       "    \"281\": \"running on treadmill\",\n",
       "    \"282\": \"sailing\",\n",
       "    \"283\": \"salsa dancing\",\n",
       "    \"284\": \"sanding floor\",\n",
       "    \"285\": \"scrambling eggs\",\n",
       "    \"286\": \"scuba diving\",\n",
       "    \"287\": \"setting table\",\n",
       "    \"288\": \"shaking hands\",\n",
       "    \"289\": \"shaking head\",\n",
       "    \"290\": \"sharpening knives\",\n",
       "    \"291\": \"sharpening pencil\",\n",
       "    \"292\": \"shaving head\",\n",
       "    \"293\": \"shaving legs\",\n",
       "    \"294\": \"shearing sheep\",\n",
       "    \"295\": \"shining shoes\",\n",
       "    \"296\": \"shooting basketball\",\n",
       "    \"297\": \"shooting goal (soccer)\",\n",
       "    \"298\": \"shot put\",\n",
       "    \"299\": \"shoveling snow\",\n",
       "    \"300\": \"shredding paper\",\n",
       "    \"301\": \"shuffling cards\",\n",
       "    \"302\": \"side kick\",\n",
       "    \"303\": \"sign language interpreting\",\n",
       "    \"304\": \"singing\",\n",
       "    \"305\": \"situp\",\n",
       "    \"306\": \"skateboarding\",\n",
       "    \"307\": \"ski jumping\",\n",
       "    \"308\": \"skiing (not slalom or crosscountry)\",\n",
       "    \"309\": \"skiing crosscountry\",\n",
       "    \"310\": \"skiing slalom\",\n",
       "    \"311\": \"skipping rope\",\n",
       "    \"312\": \"skydiving\",\n",
       "    \"313\": \"slacklining\",\n",
       "    \"314\": \"slapping\",\n",
       "    \"315\": \"sled dog racing\",\n",
       "    \"316\": \"smoking\",\n",
       "    \"317\": \"smoking hookah\",\n",
       "    \"318\": \"snatch weight lifting\",\n",
       "    \"319\": \"sneezing\",\n",
       "    \"320\": \"sniffing\",\n",
       "    \"321\": \"snorkeling\",\n",
       "    \"322\": \"snowboarding\",\n",
       "    \"323\": \"snowkiting\",\n",
       "    \"324\": \"snowmobiling\",\n",
       "    \"325\": \"somersaulting\",\n",
       "    \"326\": \"spinning poi\",\n",
       "    \"327\": \"spray painting\",\n",
       "    \"328\": \"spraying\",\n",
       "    \"329\": \"springboard diving\",\n",
       "    \"330\": \"squat\",\n",
       "    \"331\": \"sticking tongue out\",\n",
       "    \"332\": \"stomping grapes\",\n",
       "    \"333\": \"stretching arm\",\n",
       "    \"334\": \"stretching leg\",\n",
       "    \"335\": \"strumming guitar\",\n",
       "    \"336\": \"surfing crowd\",\n",
       "    \"337\": \"surfing water\",\n",
       "    \"338\": \"sweeping floor\",\n",
       "    \"339\": \"swimming backstroke\",\n",
       "    \"340\": \"swimming breast stroke\",\n",
       "    \"341\": \"swimming butterfly stroke\",\n",
       "    \"342\": \"swing dancing\",\n",
       "    \"343\": \"swinging legs\",\n",
       "    \"344\": \"swinging on something\",\n",
       "    \"345\": \"sword fighting\",\n",
       "    \"346\": \"tai chi\",\n",
       "    \"347\": \"taking a shower\",\n",
       "    \"348\": \"tango dancing\",\n",
       "    \"349\": \"tap dancing\",\n",
       "    \"350\": \"tapping guitar\",\n",
       "    \"351\": \"tapping pen\",\n",
       "    \"352\": \"tasting beer\",\n",
       "    \"353\": \"tasting food\",\n",
       "    \"354\": \"testifying\",\n",
       "    \"355\": \"texting\",\n",
       "    \"356\": \"throwing axe\",\n",
       "    \"357\": \"throwing ball\",\n",
       "    \"358\": \"throwing discus\",\n",
       "    \"359\": \"tickling\",\n",
       "    \"360\": \"tobogganing\",\n",
       "    \"361\": \"tossing coin\",\n",
       "    \"362\": \"tossing salad\",\n",
       "    \"363\": \"training dog\",\n",
       "    \"364\": \"trapezing\",\n",
       "    \"365\": \"trimming or shaving beard\",\n",
       "    \"366\": \"trimming trees\",\n",
       "    \"367\": \"triple jump\",\n",
       "    \"368\": \"tying bow tie\",\n",
       "    \"369\": \"tying knot (not on a tie)\",\n",
       "    \"370\": \"tying tie\",\n",
       "    \"371\": \"unboxing\",\n",
       "    \"372\": \"unloading truck\",\n",
       "    \"373\": \"using computer\",\n",
       "    \"374\": \"using remote controller (not gaming)\",\n",
       "    \"375\": \"using segway\",\n",
       "    \"376\": \"vault\",\n",
       "    \"377\": \"waiting in line\",\n",
       "    \"378\": \"walking the dog\",\n",
       "    \"379\": \"washing dishes\",\n",
       "    \"380\": \"washing feet\",\n",
       "    \"381\": \"washing hair\",\n",
       "    \"382\": \"washing hands\",\n",
       "    \"383\": \"water skiing\",\n",
       "    \"384\": \"water sliding\",\n",
       "    \"385\": \"watering plants\",\n",
       "    \"386\": \"waxing back\",\n",
       "    \"387\": \"waxing chest\",\n",
       "    \"388\": \"waxing eyebrows\",\n",
       "    \"389\": \"waxing legs\",\n",
       "    \"390\": \"weaving basket\",\n",
       "    \"391\": \"welding\",\n",
       "    \"392\": \"whistling\",\n",
       "    \"393\": \"windsurfing\",\n",
       "    \"394\": \"wrapping present\",\n",
       "    \"395\": \"wrestling\",\n",
       "    \"396\": \"writing\",\n",
       "    \"397\": \"yawning\",\n",
       "    \"398\": \"yoga\",\n",
       "    \"399\": \"zumba\"\n",
       "  },\n",
       "  \"image_size\": 224,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"abseiling\": 0,\n",
       "    \"air drumming\": 1,\n",
       "    \"answering questions\": 2,\n",
       "    \"applauding\": 3,\n",
       "    \"applying cream\": 4,\n",
       "    \"archery\": 5,\n",
       "    \"arm wrestling\": 6,\n",
       "    \"arranging flowers\": 7,\n",
       "    \"assembling computer\": 8,\n",
       "    \"auctioning\": 9,\n",
       "    \"baby waking up\": 10,\n",
       "    \"baking cookies\": 11,\n",
       "    \"balloon blowing\": 12,\n",
       "    \"bandaging\": 13,\n",
       "    \"barbequing\": 14,\n",
       "    \"bartending\": 15,\n",
       "    \"beatboxing\": 16,\n",
       "    \"bee keeping\": 17,\n",
       "    \"belly dancing\": 18,\n",
       "    \"bench pressing\": 19,\n",
       "    \"bending back\": 20,\n",
       "    \"bending metal\": 21,\n",
       "    \"biking through snow\": 22,\n",
       "    \"blasting sand\": 23,\n",
       "    \"blowing glass\": 24,\n",
       "    \"blowing leaves\": 25,\n",
       "    \"blowing nose\": 26,\n",
       "    \"blowing out candles\": 27,\n",
       "    \"bobsledding\": 28,\n",
       "    \"bookbinding\": 29,\n",
       "    \"bouncing on trampoline\": 30,\n",
       "    \"bowling\": 31,\n",
       "    \"braiding hair\": 32,\n",
       "    \"breading or breadcrumbing\": 33,\n",
       "    \"breakdancing\": 34,\n",
       "    \"brush painting\": 35,\n",
       "    \"brushing hair\": 36,\n",
       "    \"brushing teeth\": 37,\n",
       "    \"building cabinet\": 38,\n",
       "    \"building shed\": 39,\n",
       "    \"bungee jumping\": 40,\n",
       "    \"busking\": 41,\n",
       "    \"canoeing or kayaking\": 42,\n",
       "    \"capoeira\": 43,\n",
       "    \"carrying baby\": 44,\n",
       "    \"cartwheeling\": 45,\n",
       "    \"carving pumpkin\": 46,\n",
       "    \"catching fish\": 47,\n",
       "    \"catching or throwing baseball\": 48,\n",
       "    \"catching or throwing frisbee\": 49,\n",
       "    \"catching or throwing softball\": 50,\n",
       "    \"celebrating\": 51,\n",
       "    \"changing oil\": 52,\n",
       "    \"changing wheel\": 53,\n",
       "    \"checking tires\": 54,\n",
       "    \"cheerleading\": 55,\n",
       "    \"chopping wood\": 56,\n",
       "    \"clapping\": 57,\n",
       "    \"clay pottery making\": 58,\n",
       "    \"clean and jerk\": 59,\n",
       "    \"cleaning floor\": 60,\n",
       "    \"cleaning gutters\": 61,\n",
       "    \"cleaning pool\": 62,\n",
       "    \"cleaning shoes\": 63,\n",
       "    \"cleaning toilet\": 64,\n",
       "    \"cleaning windows\": 65,\n",
       "    \"climbing a rope\": 66,\n",
       "    \"climbing ladder\": 67,\n",
       "    \"climbing tree\": 68,\n",
       "    \"contact juggling\": 69,\n",
       "    \"cooking chicken\": 70,\n",
       "    \"cooking egg\": 71,\n",
       "    \"cooking on campfire\": 72,\n",
       "    \"cooking sausages\": 73,\n",
       "    \"counting money\": 74,\n",
       "    \"country line dancing\": 75,\n",
       "    \"cracking neck\": 76,\n",
       "    \"crawling baby\": 77,\n",
       "    \"crossing river\": 78,\n",
       "    \"crying\": 79,\n",
       "    \"curling hair\": 80,\n",
       "    \"cutting nails\": 81,\n",
       "    \"cutting pineapple\": 82,\n",
       "    \"cutting watermelon\": 83,\n",
       "    \"dancing ballet\": 84,\n",
       "    \"dancing charleston\": 85,\n",
       "    \"dancing gangnam style\": 86,\n",
       "    \"dancing macarena\": 87,\n",
       "    \"deadlifting\": 88,\n",
       "    \"decorating the christmas tree\": 89,\n",
       "    \"digging\": 90,\n",
       "    \"dining\": 91,\n",
       "    \"disc golfing\": 92,\n",
       "    \"diving cliff\": 93,\n",
       "    \"dodgeball\": 94,\n",
       "    \"doing aerobics\": 95,\n",
       "    \"doing laundry\": 96,\n",
       "    \"doing nails\": 97,\n",
       "    \"drawing\": 98,\n",
       "    \"dribbling basketball\": 99,\n",
       "    \"drinking\": 100,\n",
       "    \"drinking beer\": 101,\n",
       "    \"drinking shots\": 102,\n",
       "    \"driving car\": 103,\n",
       "    \"driving tractor\": 104,\n",
       "    \"drop kicking\": 105,\n",
       "    \"drumming fingers\": 106,\n",
       "    \"dunking basketball\": 107,\n",
       "    \"dying hair\": 108,\n",
       "    \"eating burger\": 109,\n",
       "    \"eating cake\": 110,\n",
       "    \"eating carrots\": 111,\n",
       "    \"eating chips\": 112,\n",
       "    \"eating doughnuts\": 113,\n",
       "    \"eating hotdog\": 114,\n",
       "    \"eating ice cream\": 115,\n",
       "    \"eating spaghetti\": 116,\n",
       "    \"eating watermelon\": 117,\n",
       "    \"egg hunting\": 118,\n",
       "    \"exercising arm\": 119,\n",
       "    \"exercising with an exercise ball\": 120,\n",
       "    \"extinguishing fire\": 121,\n",
       "    \"faceplanting\": 122,\n",
       "    \"feeding birds\": 123,\n",
       "    \"feeding fish\": 124,\n",
       "    \"feeding goats\": 125,\n",
       "    \"filling eyebrows\": 126,\n",
       "    \"finger snapping\": 127,\n",
       "    \"fixing hair\": 128,\n",
       "    \"flipping pancake\": 129,\n",
       "    \"flying kite\": 130,\n",
       "    \"folding clothes\": 131,\n",
       "    \"folding napkins\": 132,\n",
       "    \"folding paper\": 133,\n",
       "    \"front raises\": 134,\n",
       "    \"frying vegetables\": 135,\n",
       "    \"garbage collecting\": 136,\n",
       "    \"gargling\": 137,\n",
       "    \"getting a haircut\": 138,\n",
       "    \"getting a tattoo\": 139,\n",
       "    \"giving or receiving award\": 140,\n",
       "    \"golf chipping\": 141,\n",
       "    \"golf driving\": 142,\n",
       "    \"golf putting\": 143,\n",
       "    \"grinding meat\": 144,\n",
       "    \"grooming dog\": 145,\n",
       "    \"grooming horse\": 146,\n",
       "    \"gymnastics tumbling\": 147,\n",
       "    \"hammer throw\": 148,\n",
       "    \"headbanging\": 149,\n",
       "    \"headbutting\": 150,\n",
       "    \"high jump\": 151,\n",
       "    \"high kick\": 152,\n",
       "    \"hitting baseball\": 153,\n",
       "    \"hockey stop\": 154,\n",
       "    \"holding snake\": 155,\n",
       "    \"hopscotch\": 156,\n",
       "    \"hoverboarding\": 157,\n",
       "    \"hugging\": 158,\n",
       "    \"hula hooping\": 159,\n",
       "    \"hurdling\": 160,\n",
       "    \"hurling (sport)\": 161,\n",
       "    \"ice climbing\": 162,\n",
       "    \"ice fishing\": 163,\n",
       "    \"ice skating\": 164,\n",
       "    \"ironing\": 165,\n",
       "    \"javelin throw\": 166,\n",
       "    \"jetskiing\": 167,\n",
       "    \"jogging\": 168,\n",
       "    \"juggling balls\": 169,\n",
       "    \"juggling fire\": 170,\n",
       "    \"juggling soccer ball\": 171,\n",
       "    \"jumping into pool\": 172,\n",
       "    \"jumpstyle dancing\": 173,\n",
       "    \"kicking field goal\": 174,\n",
       "    \"kicking soccer ball\": 175,\n",
       "    \"kissing\": 176,\n",
       "    \"kitesurfing\": 177,\n",
       "    \"knitting\": 178,\n",
       "    \"krumping\": 179,\n",
       "    \"laughing\": 180,\n",
       "    \"laying bricks\": 181,\n",
       "    \"long jump\": 182,\n",
       "    \"lunge\": 183,\n",
       "    \"making a cake\": 184,\n",
       "    \"making a sandwich\": 185,\n",
       "    \"making bed\": 186,\n",
       "    \"making jewelry\": 187,\n",
       "    \"making pizza\": 188,\n",
       "    \"making snowman\": 189,\n",
       "    \"making sushi\": 190,\n",
       "    \"making tea\": 191,\n",
       "    \"marching\": 192,\n",
       "    \"massaging back\": 193,\n",
       "    \"massaging feet\": 194,\n",
       "    \"massaging legs\": 195,\n",
       "    \"massaging person's head\": 196,\n",
       "    \"milking cow\": 197,\n",
       "    \"mopping floor\": 198,\n",
       "    \"motorcycling\": 199,\n",
       "    \"moving furniture\": 200,\n",
       "    \"mowing lawn\": 201,\n",
       "    \"news anchoring\": 202,\n",
       "    \"opening bottle\": 203,\n",
       "    \"opening present\": 204,\n",
       "    \"paragliding\": 205,\n",
       "    \"parasailing\": 206,\n",
       "    \"parkour\": 207,\n",
       "    \"passing American football (in game)\": 208,\n",
       "    \"passing American football (not in game)\": 209,\n",
       "    \"peeling apples\": 210,\n",
       "    \"peeling potatoes\": 211,\n",
       "    \"petting animal (not cat)\": 212,\n",
       "    \"petting cat\": 213,\n",
       "    \"picking fruit\": 214,\n",
       "    \"planting trees\": 215,\n",
       "    \"plastering\": 216,\n",
       "    \"playing accordion\": 217,\n",
       "    \"playing badminton\": 218,\n",
       "    \"playing bagpipes\": 219,\n",
       "    \"playing basketball\": 220,\n",
       "    \"playing bass guitar\": 221,\n",
       "    \"playing cards\": 222,\n",
       "    \"playing cello\": 223,\n",
       "    \"playing chess\": 224,\n",
       "    \"playing clarinet\": 225,\n",
       "    \"playing controller\": 226,\n",
       "    \"playing cricket\": 227,\n",
       "    \"playing cymbals\": 228,\n",
       "    \"playing didgeridoo\": 229,\n",
       "    \"playing drums\": 230,\n",
       "    \"playing flute\": 231,\n",
       "    \"playing guitar\": 232,\n",
       "    \"playing harmonica\": 233,\n",
       "    \"playing harp\": 234,\n",
       "    \"playing ice hockey\": 235,\n",
       "    \"playing keyboard\": 236,\n",
       "    \"playing kickball\": 237,\n",
       "    \"playing monopoly\": 238,\n",
       "    \"playing organ\": 239,\n",
       "    \"playing paintball\": 240,\n",
       "    \"playing piano\": 241,\n",
       "    \"playing poker\": 242,\n",
       "    \"playing recorder\": 243,\n",
       "    \"playing saxophone\": 244,\n",
       "    \"playing squash or racquetball\": 245,\n",
       "    \"playing tennis\": 246,\n",
       "    \"playing trombone\": 247,\n",
       "    \"playing trumpet\": 248,\n",
       "    \"playing ukulele\": 249,\n",
       "    \"playing violin\": 250,\n",
       "    \"playing volleyball\": 251,\n",
       "    \"playing xylophone\": 252,\n",
       "    \"pole vault\": 253,\n",
       "    \"presenting weather forecast\": 254,\n",
       "    \"pull ups\": 255,\n",
       "    \"pumping fist\": 256,\n",
       "    \"pumping gas\": 257,\n",
       "    \"punching bag\": 258,\n",
       "    \"punching person (boxing)\": 259,\n",
       "    \"push up\": 260,\n",
       "    \"pushing car\": 261,\n",
       "    \"pushing cart\": 262,\n",
       "    \"pushing wheelchair\": 263,\n",
       "    \"reading book\": 264,\n",
       "    \"reading newspaper\": 265,\n",
       "    \"recording music\": 266,\n",
       "    \"riding a bike\": 267,\n",
       "    \"riding camel\": 268,\n",
       "    \"riding elephant\": 269,\n",
       "    \"riding mechanical bull\": 270,\n",
       "    \"riding mountain bike\": 271,\n",
       "    \"riding mule\": 272,\n",
       "    \"riding or walking with horse\": 273,\n",
       "    \"riding scooter\": 274,\n",
       "    \"riding unicycle\": 275,\n",
       "    \"ripping paper\": 276,\n",
       "    \"robot dancing\": 277,\n",
       "    \"rock climbing\": 278,\n",
       "    \"rock scissors paper\": 279,\n",
       "    \"roller skating\": 280,\n",
       "    \"running on treadmill\": 281,\n",
       "    \"sailing\": 282,\n",
       "    \"salsa dancing\": 283,\n",
       "    \"sanding floor\": 284,\n",
       "    \"scrambling eggs\": 285,\n",
       "    \"scuba diving\": 286,\n",
       "    \"setting table\": 287,\n",
       "    \"shaking hands\": 288,\n",
       "    \"shaking head\": 289,\n",
       "    \"sharpening knives\": 290,\n",
       "    \"sharpening pencil\": 291,\n",
       "    \"shaving head\": 292,\n",
       "    \"shaving legs\": 293,\n",
       "    \"shearing sheep\": 294,\n",
       "    \"shining shoes\": 295,\n",
       "    \"shooting basketball\": 296,\n",
       "    \"shooting goal (soccer)\": 297,\n",
       "    \"shot put\": 298,\n",
       "    \"shoveling snow\": 299,\n",
       "    \"shredding paper\": 300,\n",
       "    \"shuffling cards\": 301,\n",
       "    \"side kick\": 302,\n",
       "    \"sign language interpreting\": 303,\n",
       "    \"singing\": 304,\n",
       "    \"situp\": 305,\n",
       "    \"skateboarding\": 306,\n",
       "    \"ski jumping\": 307,\n",
       "    \"skiing (not slalom or crosscountry)\": 308,\n",
       "    \"skiing crosscountry\": 309,\n",
       "    \"skiing slalom\": 310,\n",
       "    \"skipping rope\": 311,\n",
       "    \"skydiving\": 312,\n",
       "    \"slacklining\": 313,\n",
       "    \"slapping\": 314,\n",
       "    \"sled dog racing\": 315,\n",
       "    \"smoking\": 316,\n",
       "    \"smoking hookah\": 317,\n",
       "    \"snatch weight lifting\": 318,\n",
       "    \"sneezing\": 319,\n",
       "    \"sniffing\": 320,\n",
       "    \"snorkeling\": 321,\n",
       "    \"snowboarding\": 322,\n",
       "    \"snowkiting\": 323,\n",
       "    \"snowmobiling\": 324,\n",
       "    \"somersaulting\": 325,\n",
       "    \"spinning poi\": 326,\n",
       "    \"spray painting\": 327,\n",
       "    \"spraying\": 328,\n",
       "    \"springboard diving\": 329,\n",
       "    \"squat\": 330,\n",
       "    \"sticking tongue out\": 331,\n",
       "    \"stomping grapes\": 332,\n",
       "    \"stretching arm\": 333,\n",
       "    \"stretching leg\": 334,\n",
       "    \"strumming guitar\": 335,\n",
       "    \"surfing crowd\": 336,\n",
       "    \"surfing water\": 337,\n",
       "    \"sweeping floor\": 338,\n",
       "    \"swimming backstroke\": 339,\n",
       "    \"swimming breast stroke\": 340,\n",
       "    \"swimming butterfly stroke\": 341,\n",
       "    \"swing dancing\": 342,\n",
       "    \"swinging legs\": 343,\n",
       "    \"swinging on something\": 344,\n",
       "    \"sword fighting\": 345,\n",
       "    \"tai chi\": 346,\n",
       "    \"taking a shower\": 347,\n",
       "    \"tango dancing\": 348,\n",
       "    \"tap dancing\": 349,\n",
       "    \"tapping guitar\": 350,\n",
       "    \"tapping pen\": 351,\n",
       "    \"tasting beer\": 352,\n",
       "    \"tasting food\": 353,\n",
       "    \"testifying\": 354,\n",
       "    \"texting\": 355,\n",
       "    \"throwing axe\": 356,\n",
       "    \"throwing ball\": 357,\n",
       "    \"throwing discus\": 358,\n",
       "    \"tickling\": 359,\n",
       "    \"tobogganing\": 360,\n",
       "    \"tossing coin\": 361,\n",
       "    \"tossing salad\": 362,\n",
       "    \"training dog\": 363,\n",
       "    \"trapezing\": 364,\n",
       "    \"trimming or shaving beard\": 365,\n",
       "    \"trimming trees\": 366,\n",
       "    \"triple jump\": 367,\n",
       "    \"tying bow tie\": 368,\n",
       "    \"tying knot (not on a tie)\": 369,\n",
       "    \"tying tie\": 370,\n",
       "    \"unboxing\": 371,\n",
       "    \"unloading truck\": 372,\n",
       "    \"using computer\": 373,\n",
       "    \"using remote controller (not gaming)\": 374,\n",
       "    \"using segway\": 375,\n",
       "    \"vault\": 376,\n",
       "    \"waiting in line\": 377,\n",
       "    \"walking the dog\": 378,\n",
       "    \"washing dishes\": 379,\n",
       "    \"washing feet\": 380,\n",
       "    \"washing hair\": 381,\n",
       "    \"washing hands\": 382,\n",
       "    \"water skiing\": 383,\n",
       "    \"water sliding\": 384,\n",
       "    \"watering plants\": 385,\n",
       "    \"waxing back\": 386,\n",
       "    \"waxing chest\": 387,\n",
       "    \"waxing eyebrows\": 388,\n",
       "    \"waxing legs\": 389,\n",
       "    \"weaving basket\": 390,\n",
       "    \"welding\": 391,\n",
       "    \"whistling\": 392,\n",
       "    \"windsurfing\": 393,\n",
       "    \"wrapping present\": 394,\n",
       "    \"wrestling\": 395,\n",
       "    \"writing\": 396,\n",
       "    \"yawning\": 397,\n",
       "    \"yoga\": 398,\n",
       "    \"zumba\": 399\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-06,\n",
       "  \"model_type\": \"timesformer\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_channels\": 3,\n",
       "  \"num_frames\": 8,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"patch_size\": 16,\n",
       "  \"qkv_bias\": true,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.26.1\"\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config#.num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7612a650-4c4d-4f1a-a7f7-11c22ff6b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = create_video_transform(\n",
    "    mode='train',\n",
    "    num_samples=8,#model_config.num_frames,\n",
    "    video_mean = tuple(image_processor_config.image_mean),\n",
    "    video_std = tuple(image_processor_config.image_std),\n",
    "    crop_size = tuple(image_processor_config.crop_size.values())\n",
    ")\n",
    "\n",
    "val_transform = create_video_transform(\n",
    "    mode='val',\n",
    "    num_samples=8, #model_config.num_frames,\n",
    "    video_mean = tuple(image_processor_config.image_mean),\n",
    "    video_std = tuple(image_processor_config.image_std),\n",
    "    crop_size = tuple(image_processor_config.crop_size.values())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d1b230d-4ca8-43ce-b7ea-0003c8352f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VideoDataset(train_df_for_dataset, transform=train_transform)\n",
    "val_dataset = VideoDataset(val_df_for_dataset, transform=val_transform)\n",
    "test_dataset = VideoDataset(test_df_for_dataset, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4b25026-b607-4f60-a500-49d1ee93fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = MultilabelBalancedRandomSampler(train_multi_hot_for_sampler)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size= config['batch_size'], sampler=train_sampler)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = config['batch_size']*2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = config['batch_size']*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69747543-ce8b-4f0c-aa58-de46c616490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PLVideoModel(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.learning_rate = config['learning_rate']\n",
    "        self.model = AutoModel.from_pretrained(config['model_name'])\n",
    "        self.classifiers = nn.ModuleList([\n",
    "            nn.LazyLinear(n_class) for n_class in config['n_classes']\n",
    "        ])\n",
    "        self.loss = FocalLoss('multiclass')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x).last_hidden_state.mean(dim=1)\n",
    "        x_out = [classifier(x) for classifier in self.classifiers]\n",
    "        return x_out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        video, label, label_split = batch['video'], batch['label'], batch['label_split']\n",
    "        y_hats = self.forward(batch[\"video\"])\n",
    "        loss = sum([self.loss(y_hats[i], batch[\"label_split\"][:,i]) for i in range(len(self.config['n_classes']))])\n",
    "        loss = loss/len(self.config['n_classes'])\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        video, label, label_split = batch['video'], batch['label'], batch['label_split']\n",
    "        y_hats = self.forward(batch[\"video\"])\n",
    "        step_output = [*y_hats, label]\n",
    "        return step_output\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        video, _, _ = batch['video'], batch['label'], batch['label_split']\n",
    "        y_hats = self.forward(batch[\"video\"])\n",
    "        step_output = y_hats\n",
    "        return step_output\n",
    "\n",
    "    def validation_epoch_end(self, step_outputs):\n",
    "        pred1, pred2, pred3, pred4, label = [], [], [], [], []\n",
    "        for step_output in step_outputs:\n",
    "            pred1.append(step_output[0])\n",
    "            pred2.append(step_output[1])\n",
    "            pred3.append(step_output[2])\n",
    "            pred4.append(step_output[3])\n",
    "            label.append(step_output[4])\n",
    "            \n",
    "        pred1 = torch.cat(pred1).argmax(1)\n",
    "        pred2 = torch.cat(pred2).argmax(1)\n",
    "        pred3 = torch.cat(pred3).argmax(1)\n",
    "        pred4 = torch.cat(pred4).argmax(1)\n",
    "        label = torch.cat(label).tolist()\n",
    "\n",
    "        pred = torch.stack([pred1,pred2,pred3,pred4],dim=1).cpu().detach().numpy().tolist()\n",
    "        pred = list(map(lambda x: self.config['label_reverse_dict'].get(tuple(x),0),pred))\n",
    "        \n",
    "        score = f1_score(label,pred, average='macro')\n",
    "        self.log(\"val_score\", score)\n",
    "        return score\n",
    "    \n",
    "    def post_preproc(self, step_outputs):\n",
    "        pred1, pred2, pred3, pred4 = [], [], [], []\n",
    "        for step_output in step_outputs:\n",
    "            pred1.append(step_output[0])\n",
    "            pred2.append(step_output[1])\n",
    "            pred3.append(step_output[2])\n",
    "            pred4.append(step_output[3])\n",
    "            \n",
    "        pred1 = torch.cat(pred1).argmax(1)\n",
    "        pred2 = torch.cat(pred2).argmax(1)\n",
    "        pred3 = torch.cat(pred3).argmax(1)\n",
    "        pred4 = torch.cat(pred4).argmax(1)\n",
    "\n",
    "        pred = torch.stack([pred1,pred2,pred3,pred4],dim=1).cpu().detach().numpy().tolist()\n",
    "        pred = list(map(lambda x: self.config['label_reverse_dict'].get(tuple(x),0),pred))\n",
    "\n",
    "        return pred\n",
    "            \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Apollo(self.parameters(), lr=self.learning_rate)\n",
    "        return [optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38dca735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.multiprocessing as mp\n",
    "# try:\n",
    "#     mp.set_start_method('spawn')\n",
    "# except RuntimeError:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1665d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool, set_start_method\n",
    "\n",
    "# set_start_method('spawn')\n",
    "# with Pool() as pool:\n",
    "# \tpool.map(foo, [1,2,3], [4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbd5dbf9-b7f7-404b-9843-faae40e7eb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/timesformer-base-finetuned-k400 were not used when initializing TimesformerModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing TimesformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TimesformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/ict04/.conda/envs/CH_TEST/lib/python3.10/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | model       | TimesformerModel | 121 M \n",
      "1 | classifiers | ModuleList       | 0     \n",
      "2 | loss        | FocalLoss        | 0     \n",
      "-------------------------------------------------\n",
      "121 M     Trainable params\n",
      "0         Non-trainable params\n",
      "121 M     Total params\n",
      "242.518   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301349c5568f4badaf69fb7fb32713dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ict04/.conda/envs/CH_TEST/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ict04/.conda/envs/CH_TEST/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01df0702116433e9b360e5deb8ce769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e38c24357bd474fb734a1321f092b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721c86f6d9254af6813ddf91d1fb2d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150a90db23d846c587911c8e5b3a308f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0fcb1a821d4e689d5a0b2d2913f621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a3977c2fa843d7bd764d089406cecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b175ebcd99634373a86b8e89c997f97f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b367948f154d5681d5538dd5fb82c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1272067d2df42c0bdf8925564ba67f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff11db0c673b42e888a00fa2e5d57279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_score',\n",
    "    dirpath=config['checkpoint_dir'],\n",
    "    filename=f'{config[\"model_name\"]}'+'-{epoch:02d}-{train_loss:.4f}-{val_score:.4f}',\n",
    "    mode='max'\n",
    ")\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"train_loss\",\n",
    "    patience=3,\n",
    "    verbose=False,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "pl_video_model = PLVideoModel(config)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,\n",
    "    accelerator='auto', \n",
    "    precision=16,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback]\n",
    "                    \n",
    ")\n",
    "\n",
    "trainer.fit(pl_video_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "531d95da-c86f-44e5-9a56-b16505bdc5d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ict04/MINITEST/CH/checkpoint/facebook/timesformer-base-finetuned-k400-epoch=08-train_loss=0.1353-val_score=0.5356.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pl_video_model_pretrained \u001b[39m=\u001b[39m PLVideoModel\u001b[39m.\u001b[39;49mload_from_checkpoint(\n\u001b[1;32m      2\u001b[0m     \u001b[39m#\"./checkpoint/facebook/timesformer-base-finetuned-k400-epoch=08-train_loss=0.1318-val_score=0.5356.ckpt\",\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39m/home/ict04/MINITEST/CH/checkpoint/facebook/timesformer-base-finetuned-k400-epoch=08-train_loss=0.1353-val_score=0.5356.ckpt\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     config\u001b[39m=\u001b[39;49mconfig\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m trainer \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mTrainer(accelerator\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m pred \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mpredict(pl_video_model_pretrained, test_dataloader)\n",
      "File \u001b[0;32m~/.conda/envs/CH_TEST/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:139\u001b[0m, in \u001b[0;36mModelIO.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_from_checkpoint\u001b[39m(\n\u001b[1;32m     61\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     67\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Self:  \u001b[39m# type: ignore[valid-type]\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39m    Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[39m    it stores the arguments passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m        y_hat = pretrained_model(x)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_from_checkpoint(\n\u001b[1;32m    140\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[1;32m    141\u001b[0m         checkpoint_path,\n\u001b[1;32m    142\u001b[0m         map_location,\n\u001b[1;32m    143\u001b[0m         hparams_file,\n\u001b[1;32m    144\u001b[0m         strict,\n\u001b[1;32m    145\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    146\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/CH_TEST/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:160\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     map_location \u001b[39m=\u001b[39m cast(_MAP_LOCATION_TYPE, \u001b[39mlambda\u001b[39;00m storage, loc: storage)\n\u001b[1;32m    159\u001b[0m \u001b[39mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m--> 160\u001b[0m     checkpoint \u001b[39m=\u001b[39m pl_load(checkpoint_path, map_location\u001b[39m=\u001b[39;49mmap_location)\n\u001b[1;32m    162\u001b[0m \u001b[39m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m    163\u001b[0m checkpoint \u001b[39m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m    164\u001b[0m     checkpoint, checkpoint_path\u001b[39m=\u001b[39m(checkpoint_path \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(checkpoint_path, (\u001b[39mstr\u001b[39m, Path)) \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/CH_TEST/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:47\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     43\u001b[0m         \u001b[39mstr\u001b[39m(path_or_url),\n\u001b[1;32m     44\u001b[0m         map_location\u001b[39m=\u001b[39mmap_location,  \u001b[39m# type: ignore[arg-type] # upstream annotation is not correct\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     )\n\u001b[1;32m     46\u001b[0m fs \u001b[39m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 47\u001b[0m \u001b[39mwith\u001b[39;00m fs\u001b[39m.\u001b[39;49mopen(path_or_url, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     48\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mload(f, map_location\u001b[39m=\u001b[39mmap_location)\n",
      "File \u001b[0;32m~/.conda/envs/CH_TEST/lib/python3.10/site-packages/fsspec/spec.py:1135\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1134\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> 1135\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[1;32m   1136\u001b[0m         path,\n\u001b[1;32m   1137\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   1138\u001b[0m         block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m   1139\u001b[0m         autocommit\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m   1140\u001b[0m         cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   1141\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1142\u001b[0m     )\n\u001b[1;32m   1143\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1144\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/.conda/envs/CH_TEST/lib/python3.10/site-packages/fsspec/implementations/local.py:183\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_mkdir \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m    182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent(path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/CH_TEST/lib/python3.10/site-packages/fsspec/implementations/local.py:285\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    284\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 285\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open()\n",
      "File \u001b[0;32m~/.conda/envs/CH_TEST/lib/python3.10/site-packages/fsspec/implementations/local.py:290\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\u001b[39m.\u001b[39mclosed:\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautocommit \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode:\n\u001b[0;32m--> 290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    291\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression:\n\u001b[1;32m    292\u001b[0m             compress \u001b[39m=\u001b[39m compr[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ict04/MINITEST/CH/checkpoint/facebook/timesformer-base-finetuned-k400-epoch=08-train_loss=0.1353-val_score=0.5356.ckpt'"
     ]
    }
   ],
   "source": [
    "pl_video_model_pretrained = PLVideoModel.load_from_checkpoint(\n",
    "    #\"./checkpoint/facebook/timesformer-base-finetuned-k400-epoch=08-train_loss=0.1318-val_score=0.5356.ckpt\",\n",
    "    '/home/ict04/MINITEST/CH/checkpoint/facebook/timesformer-base-finetuned-k400-epoch=08-train_loss=0.1353-val_score=0.5356.ckpt',\n",
    "    config=config\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(accelerator='auto')\n",
    "pred = trainer.predict(pl_video_model_pretrained, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae171f4-24fe-4428-94e7-e2e920b20b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_post_proc = pl_video_model_pretrained.post_preproc(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53206209-b381-44e9-a27b-815db93db13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv(f\"{config['data_dir']}/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c78f9-1a7a-4a5b-8e32-b768e43ea392",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['label'] = pred_post_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc42ee-4233-496b-98df-d7b08f0abe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(f\"./pretrained_submit_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a435a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CH_TEST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "3708ecb67a3b8f2d8073a2999601f1c0bb240db3c4d5b249cf54830cc2961f18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
